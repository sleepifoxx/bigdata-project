# ğŸ” Real-time Fraud Detection System

Há»‡ thá»‘ng phÃ¡t hiá»‡n giao dá»‹ch lá»«a Ä‘áº£o real-time vá»›i Kafka, Spark MLlib vÃ  Plotly Dash.

## ğŸ“Š Kiáº¿n trÃºc há»‡ thá»‘ng

```
CSV File (HDFS)
    â†“
Kafka Producer (giáº£ láº­p realtime)
    â†“
Kafka Topic: "transactions"
    â†“
Spark Streaming + MLlib (dá»± Ä‘oÃ¡n fraud)
    â†“
Kafka Topic: "predictions"
    â†“
Dashboard (Plotly Dash - visualize realtime)
```

## ğŸ—‚ï¸ Cáº¥u trÃºc Files

```
â”œâ”€â”€ kafka_producer.py          # Producer: CSV â†’ Kafka
â”œâ”€â”€ spark_consumer.py          # Consumer: Kafka â†’ ML Model â†’ Kafka
â”œâ”€â”€ dashboard.py               # Dashboard: Kafka â†’ Visualize
â”œâ”€â”€ requirements_dashboard.txt # Python dependencies cho dashboard
â”œâ”€â”€ run_system.sh             # Script cháº¡y há»‡ thá»‘ng
â”œâ”€â”€ gbt_fraud_model/          # GBT model Ä‘Ã£ train (tá»« train.ipynb)
â””â”€â”€ spark_scaler_model/       # Scaler model (tá»« train.ipynb)
```

## ğŸš€ CÃ¡ch cháº¡y

### BÆ°á»›c 1: Äáº£m báº£o Ä‘Ã£ train model

Cháº¡y notebook `train.ipynb` Ä‘á»ƒ train model vÃ  táº¡o:
- `gbt_fraud_model/`
- `spark_scaler_model/`

### BÆ°á»›c 2: Chuáº©n bá»‹ dá»¯ liá»‡u

Upload file CSV lÃªn HDFS:
```bash
# Copy file vÃ o namenode container
docker cp paysim_realtime.csv namenode:/tmp/

# Upload lÃªn HDFS
docker exec -it namenode bash
hdfs dfs -mkdir -p /data/input
hdfs dfs -put /tmp/paysim_realtime.csv /data/input/
hdfs dfs -ls /data/input
```

### BÆ°á»›c 3: Cháº¡y há»‡ thá»‘ng (3 terminals)

#### **Terminal 1: Kafka Producer**
```bash
spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 \
  kafka_producer.py
```

**Chá»©c nÄƒng:**
- Äá»c CSV tá»« HDFS (`/data/input/paysim_realtime.csv`)
- Gá»­i tá»«ng dÃ²ng vÃ o Kafka topic `transactions` (giáº£ láº­p realtime)
- Delay 0.1 giÃ¢y giá»¯a cÃ¡c transactions

#### **Terminal 2: Spark Consumer**
```bash
python spark_consumer_batch.py
```

**Chá»©c nÄƒng:**
- Nháº­n transactions tá»« Kafka topic `transactions`
- Táº¡o features (giá»‘ng preprocessing)
- Dá»± Ä‘oÃ¡n fraud vá»›i GBT model Ä‘Ã£ train
- Gá»­i káº¿t quáº£ vÃ o Kafka topic `predictions`

#### **Terminal 3: Dashboard**
```bash
# Install dependencies
pip install -r requirements.txt

# Run dashboard
python dashboard.py
```

**Chá»©c nÄƒng:**
- Nháº­n predictions tá»« Kafka topic `predictions`
- Hiá»ƒn thá»‹ dashboard realtime táº¡i http://localhost:8050

### Hoáº·c dÃ¹ng script tá»± Ä‘á»™ng:
```bash
chmod +x run_system.sh
./run_system.sh
```

## ğŸ“Š Dashboard Features

Dashboard hiá»ƒn thá»‹:

### 1. **Metrics Cards**
- Total Transactions
- Fraud Detected
- Fraud Rate (%)
- Total Amount ($)

### 2. **Charts**
- **Transaction Timeline**: Biá»ƒu Ä‘á»“ scatter theo thá»i gian (phÃ¢n biá»‡t normal/fraud)
- **Fraud Distribution**: Sá»‘ lÆ°á»£ng fraud theo loáº¡i giao dá»‹ch
- **Amount Distribution**: Box plot so sÃ¡nh amount cá»§a normal vs fraud
- **Confusion Matrix**: Ma tráº­n Ä‘Ã¡nh giÃ¡ performance

### 3. **Recent Transactions Table**
- 20 giao dá»‹ch gáº§n nháº¥t
- Highlight mÃ u Ä‘á» cho fraud alerts
- Hiá»ƒn thá»‹ prediction probability

## âš™ï¸ Cáº¥u hÃ¬nh

### kafka_producer.py
```python
HDFS_PATH = "hdfs://namenode:9000/data/input/paysim_realtime.csv"
KAFKA_BROKER = "kafka:9092"
KAFKA_TOPIC = "transactions"
DELAY_SECONDS = 1  # Thá»i gian delay giá»¯a cÃ¡c transactions
```

### spark_consumer.py
```python
KAFKA_BROKER = "kafka:9092"
INPUT_TOPIC = "transactions"
OUTPUT_TOPIC = "predictions"
BEST_THRESHOLD = 0.50  # NgÆ°á»¡ng phÃ¢n loáº¡i fraud (tá»« training)
```

### dashboard.py
```python
KAFKA_BROKER = "kafka:9092"
KAFKA_TOPIC = "predictions"
MAX_POINTS = 100  # Sá»‘ Ä‘iá»ƒm tá»‘i Ä‘a trÃªn biá»ƒu Ä‘á»“
```

## ğŸ”§ Troubleshooting

### 1. Lá»—i káº¿t ná»‘i Kafka
```bash
# Check Kafka container
docker ps | grep kafka

# Check Kafka topics
docker exec -it kafka kafka-topics --list --bootstrap-server localhost:9092

# Táº¡o topic thá»§ cÃ´ng (náº¿u cáº§n)
docker exec -it kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic transactions \
  --partitions 1 \
  --replication-factor 1
```

### 2. Lá»—i load model
```bash
# Äáº£m báº£o model Ä‘Ã£ Ä‘Æ°á»£c train vÃ  lÆ°u
ls -la gbt_fraud_model/
ls -la spark_scaler_model/

# Náº¿u chÆ°a cÃ³, cháº¡y train.ipynb
```

### 3. Dashboard khÃ´ng hiá»ƒn thá»‹ dá»¯ liá»‡u
```bash
# Check logs cá»§a consumer
# Äáº£m báº£o consumer Ä‘ang gá»­i vÃ o topic "predictions"

# Check Kafka messages
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic predictions \
  --from-beginning
```

### 4. Lá»—i HDFS connection
```bash
# Check namenode
docker exec -it namenode hdfs dfsadmin -report

# Check file tá»“n táº¡i
docker exec -it namenode hdfs dfs -ls /data/input/
```

## ğŸ“ˆ Performance Tips

1. **TÄƒng tá»‘c Ä‘á»™ streaming**: Giáº£m `DELAY_SECONDS` trong producer
2. **TÄƒng buffer size**: TÄƒng `MAX_POINTS` trong dashboard
3. **Batch processing**: Modify consumer Ä‘á»ƒ xá»­ lÃ½ batch thay vÃ¬ tá»«ng record

## ğŸ¯ Má»¥c tiÃªu Ä‘áº¡t Ä‘Æ°á»£c

âœ… **Real-time streaming**: Giáº£ láº­p transactions tá»« CSV  
âœ… **ML Prediction**: Dá»± Ä‘oÃ¡n fraud vá»›i Spark MLlib GBT model  
âœ… **Kafka Pipeline**: Producer â†’ Consumer vá»›i 2 topics  
âœ… **Dashboard**: Visualize realtime vá»›i Plotly Dash  
âœ… **Alerts**: Cáº£nh bÃ¡o fraud transactions  
âœ… **Metrics**: Theo dÃµi performance (confusion matrix, fraud rate)  

## ğŸ“ Notes

- System cháº¡y trong Docker containers (theo docker-compose.yml)
- Producer giáº£ láº­p realtime báº±ng cÃ¡ch delay 1s giá»¯a cÃ¡c transactions
- Model Ä‘Ã£ Ä‘Æ°á»£c train vá»›i GBTClassifier (Spark MLlib)
- Dashboard tá»± Ä‘á»™ng update má»—i 1 giÃ¢y
- Há»— trá»£ xá»­ lÃ½ imbalanced data vá»›i weighted training

## ğŸ”— URLs

- **Dashboard**: http://localhost:8050
- **Spark Master UI**: http://localhost:8080
- **Spark Worker UI**: http://localhost:8081
- **HDFS NameNode UI**: http://localhost:9870

## ğŸ“§ LiÃªn há»‡

Náº¿u cÃ³ váº¥n Ä‘á», check logs trong tá»«ng terminal Ä‘á»ƒ debug.

---
**ChÃºc báº¡n thÃ nh cÃ´ng! ğŸ‰**
