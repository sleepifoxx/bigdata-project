# ğŸš€ QUICK START GUIDE

## BÆ°á»›c 1: Chuáº©n bá»‹ model (cháº¡y 1 láº§n duy nháº¥t)

```bash
# Má»Ÿ vÃ  cháº¡y toÃ n bá»™ notebook train.ipynb
# Notebook nÃ y sáº½ táº¡o:
# - gbt_fraud_model/
# - spark_scaler_model/
```

Hoáº·c má»Ÿ Jupyter vÃ  cháº¡y: http://localhost:8888

## BÆ°á»›c 2: Chuáº©n bá»‹ dá»¯ liá»‡u

```bash
# Copy file CSV vÃ o namenode container
docker cp /path/to/paysim_realtime.csv namenode:/tmp/

# Upload lÃªn HDFS
docker exec -it namenode bash
hdfs dfs -mkdir -p /data/input
hdfs dfs -put /tmp/paysim_realtime.csv /data/input/
hdfs dfs -ls /data/input/
exit
```

## BÆ°á»›c 3: Kiá»ƒm tra models

```bash
python check_models.py
```

## BÆ°á»›c 4: Táº¡o Kafka topics (náº¿u chÆ°a cÃ³)

```bash
chmod +x kafka_monitor.sh
./kafka_monitor.sh
# Chá»n option 4 Ä‘á»ƒ táº¡o topics
```

## BÆ°á»›c 5: Cháº¡y há»‡ thá»‘ng

### CÃ¡ch 1: Script tá»± Ä‘á»™ng (dÃ¹ng tmux)
```bash
chmod +x start_all.sh
./start_all.sh
```

### CÃ¡ch 2: Cháº¡y thá»§ cÃ´ng (3 terminals riÃªng biá»‡t)

**Terminal 1 - Producer:**
```bash
spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 kafka_producer.py
```

**Terminal 2 - Consumer:**
```bash
spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 spark_consumer.py
```

**Terminal 3 - Dashboard:**
```bash
pip install -r requirements_dashboard.txt
python dashboard.py
```

### CÃ¡ch 3: DÃ¹ng menu script
```bash
chmod +x run_system.sh
./run_system.sh
# Chá»n component muá»‘n cháº¡y
```

## BÆ°á»›c 6: Xem Dashboard

Má»Ÿ trÃ¬nh duyá»‡t vÃ  truy cáº­p:
```
http://localhost:8050
```

## ğŸ¯ Káº¿t quáº£ mong Ä‘á»£i

Dashboard sáº½ hiá»ƒn thá»‹:
- âœ… Metrics: Total transactions, Fraud count, Fraud rate
- ğŸ“Š Charts: Timeline, Distribution, Confusion Matrix
- ğŸ“‹ Table: Recent 20 transactions
- ğŸš¨ Fraud alerts vá»›i highlight mÃ u Ä‘á»

## ğŸ”§ Troubleshooting

### Lá»—i: Models not found
```bash
# Cháº¡y train.ipynb Ä‘á»ƒ táº¡o models
# Hoáº·c check:
ls -la gbt_fraud_model/
ls -la spark_scaler_model/
```

### Lá»—i: Kafka connection refused
```bash
# Check Kafka Ä‘ang cháº¡y
docker ps | grep kafka

# Restart Kafka
docker-compose restart kafka zookeeper
```

### Lá»—i: File not found on HDFS
```bash
# Check file trÃªn HDFS
docker exec -it namenode hdfs dfs -ls /data/input/

# Upload láº¡i náº¿u cáº§n
docker exec -it namenode hdfs dfs -put /tmp/paysim_realtime.csv /data/input/
```

### Dashboard khÃ´ng nháº­n data
```bash
# Check Spark consumer cÃ³ cháº¡y khÃ´ng
# Check logs xem cÃ³ messages trong Kafka khÃ´ng

# Monitor Kafka topic
./kafka_monitor.sh
# Chá»n option 2 hoáº·c 3 Ä‘á»ƒ xem messages
```

## ğŸ“Š Monitor há»‡ thá»‘ng

### Spark UI
- Spark Master: http://localhost:8080
- Spark Worker: http://localhost:8081

### HDFS
- NameNode UI: http://localhost:9870

### Dashboard
- Fraud Detection: http://localhost:8050

## â¹ï¸ Dá»«ng há»‡ thá»‘ng

```bash
# Náº¿u dÃ¹ng tmux
tmux kill-session -t fraud_detection

# Náº¿u cháº¡y thá»§ cÃ´ng
# Nháº¥n Ctrl+C á»Ÿ má»—i terminal
```

## ğŸ‰ HoÃ n thÃ nh!

Há»‡ thá»‘ng realtime fraud detection Ä‘Ã£ sáºµn sÃ ng!

---
**LÆ°u Ã½:** 
- Producer sáº½ gá»­i má»—i 1 giÃ¢y 1 transaction (cÃ³ thá»ƒ thay Ä‘á»•i DELAY_SECONDS)
- Dashboard tá»± Ä‘á»™ng update má»—i 1 giÃ¢y
- Model dá»± Ä‘oÃ¡n vá»›i threshold = 0.50 (cÃ³ thá»ƒ thay Ä‘á»•i BEST_THRESHOLD)
