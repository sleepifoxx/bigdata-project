# ğŸ“– HÆ°á»›ng dáº«n Cháº¡y Há»‡ thá»‘ng - Run Guide

HÆ°á»›ng dáº«n tá»«ng bÆ°á»›c Ä‘á»ƒ cháº¡y toÃ n bá»™ há»‡ thá»‘ng Big Data Analytics Platform.

## âš ï¸ Quan trá»ng - Vá» Container

**Báº¡n Ä‘ang á»Ÿ trong container `pyspark-notebook`**

- âœ… CÃ“ THá»‚: Cháº¡y Python scripts, Spark jobs, truy cáº­p services
- âŒ KHÃ”NG THá»‚: Cháº¡y `docker` commands, quáº£n lÃ½ containers
- ğŸ”— Káº¿t ná»‘i: DÃ¹ng service names (kafka, redis, namenode, spark-master)

**Äá»ƒ quáº£n lÃ½ Docker containers:**
```bash
# Exit khá»i container
exit

# TrÃªn host machine
docker-compose ps
docker-compose logs <service>
docker-compose restart <service>

# VÃ o láº¡i container
docker exec -it pyspark-notebook bash
```

## ğŸ¯ Má»¥c tiÃªu

Cháº¡y Ä‘áº§y Ä‘á»§ há»‡ thá»‘ng gá»“m:
1. Market Risk Monitoring (chá»©ng khoÃ¡n)
2. Fraud Detection (gian láº­n)
3. Real-time Dashboard

## ğŸ“‹ Checklist TrÆ°á»›c khi Báº¯t Ä‘áº§u

### 1. Kiá»ƒm tra Services (tá»« Host Machine)

```bash
# TrÃªn host, khÃ´ng pháº£i trong container
docker-compose ps

# Cáº§n tháº¥y cÃ¡c services running:
# âœ“ zookeeper
# âœ“ kafka
# âœ“ redis
# âœ“ namenode, datanode1, datanode2
# âœ“ spark-master, spark-worker
# âœ“ pyspark-notebook
```

Náº¿u chÆ°a start:
```bash
docker-compose up -d
```

### 2. Kiá»ƒm tra Káº¿t ná»‘i (trong Container)

```python
# Test Kafka
from kafka import KafkaProducer
producer = KafkaProducer(bootstrap_servers=['kafka:9092'])
print("âœ… Kafka OK")

# Test Redis
import redis
r = redis.Redis(host='redis', port=6379, decode_responses=True)
print(r.ping())  # True
print("âœ… Redis OK")

# Test Spark
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("test").getOrCreate()
print("âœ… Spark OK")
spark.stop()
```

### 3. CÃ i Ä‘áº·t Python Packages

```bash
cd /home/jovyan/work
pip install -r requirements.txt
```

Packages cáº§n thiáº¿t:
- kafka-python
- redis
- vnstock3
- dash
- plotly
- pandas

## ğŸƒ Cháº¡y Há»‡ thá»‘ng

### OPTION 1: Cháº¡y Tá»«ng Module (Recommended)

Má»Ÿ nhiá»u terminal vÃ  cháº¡y tá»«ng pháº§n riÃªng biá»‡t.

#### Terminal 1ï¸âƒ£: Market Risk Producer

```bash
cd /home/jovyan/work/market_risk
python get_finance_data.py
```

**Output:**
```
VIETNAM STOCK MARKET DATA PRODUCER
Kafka Producer initialized. Topic: vietnam_stocks
Báº¯t Ä‘áº§u thu tháº­p dá»¯ liá»‡u cho 10 mÃ£ chá»©ng khoÃ¡n
ÄÃ£ láº¥y Ä‘Æ°á»£c 10 mÃ£ chá»©ng khoÃ¡n
Sent VCB -> Topic: vietnam_stocks, Partition: 0, Offset: 123
...
```

**Chá»©c nÄƒng:**
- Láº¥y dá»¯ liá»‡u tá»« vnstock API
- 10 mÃ£: VCB, VHM, VIC, HPG, TCB, ACB, VNM, BID, GAS, MSN
- Táº§n suáº¥t: Má»—i 15 giÃ¢y
- Gá»­i vÃ o Kafka topic: `vietnam_stocks`

**Äá»ƒ dá»«ng:** Ctrl+C

#### Terminal 2ï¸âƒ£: Market Risk Consumer

```bash
cd /home/jovyan/work/market_risk
python spark_consumer.py
```

**Output:**
```
SPARK STREAMING CONSUMER - VIETNAM STOCK MARKET
Spark Session created successfully
Connected to Kafka topic: vietnam_stocks
Redis output stream started
Console output stream started
Streaming queries are running. Press Ctrl+C to stop.
-------------------------------------------
Batch: 0
-------------------------------------------
|symbol|company_name|price|change_pct|volume|...
```

**Chá»©c nÄƒng:**
- Nháº­n dá»¯ liá»‡u tá»« Kafka topic `vietnam_stocks`
- TÃ­nh toÃ¡n risk metrics (volatility, foreign flow, price position)
- LÆ°u vÃ o Redis database
- Hiá»ƒn thá»‹ processed data trong console
- Simplified version Ä‘á»ƒ trÃ¡nh timestamp watermark issues

**Äá»ƒ dá»«ng:** Ctrl+C (sáº½ stop táº¥t cáº£ queries gracefully)

**âš ï¸ LÆ°u Ã½**: Náº¿u khÃ´ng tháº¥y dá»¯ liá»‡u, Ä‘áº£m báº£o Market Risk Producer Ä‘ang cháº¡y vÃ  gá»­i data.

#### Terminal 3ï¸âƒ£: Fraud Detection Producer

**âš ï¸ Cáº§n chuáº©n bá»‹ trÆ°á»›c:**

1. **Upload dá»¯ liá»‡u lÃªn HDFS** (tá»« host machine):

```bash
# Táº¡o thÆ° má»¥c
docker exec namenode hdfs dfs -mkdir -p /data/input

# Upload file (giáº£ sá»­ cÃ³ file paysim_realtime.csv)
docker exec namenode hdfs dfs -put paysim_realtime.csv /data/input/

# Kiá»ƒm tra
docker exec namenode hdfs dfs -ls /data/input/
```

2. **Train ML Model** (trong container):

```bash
cd /home/jovyan/work/fraud_detection
jupyter notebook
# Má»Ÿ vÃ  cháº¡y preprocessing.ipynb
# Má»Ÿ vÃ  cháº¡y train.ipynb
# Sáº½ táº¡o: gbt_fraud_model/ vÃ  spark_scaler_model/
```

3. **Cháº¡y Producer**:

```bash
cd /home/jovyan/work/fraud_detection
python realtime_producer.py
```

**Output:**
```
FRAUD DETECTION REAL-TIME PRODUCER
ÄÃ£ Ä‘á»c 50,000 giao dá»‹ch tá»« HDFS
Tá»‘c Ä‘á»™: 5 giao dá»‹ch/giÃ¢y
Progress: 100/50,000 (0.2%) - Sent: 100
...
```

**Äá»ƒ dá»«ng:** Ctrl+C

#### Terminal 4ï¸âƒ£: Fraud Detection Consumer

```bash
cd /home/jovyan/work/fraud_detection
python realtime_consumer.py
```

**Output:**
```
FRAUD DETECTION REAL-TIME CONSUMER
Loading GBT model from: gbt_fraud_model
âœ… GBT model loaded successfully
âœ… Connected to Kafka
âœ… Fraud predictions Redis stream started
FRAUD_ALERTS:
TX #12345 - CASH_OUT - $500,000 - Probability: 87.3%
...
```

**Äá»ƒ dá»«ng:** Ctrl+C

#### Terminal 5ï¸âƒ£: Dashboard

```bash
cd /home/jovyan/work
python dashboard.py
```

**Output:**
```
ğŸš€ Starting Real-time Dashboard
Dashboard URL: http://localhost:8050
Press Ctrl+C to stop
Dash is running on http://0.0.0.0:8050/
```

**Truy cáº­p:** 
- Trong container: http://localhost:8050
- Tá»« host: http://localhost:8050

**Äá»ƒ dá»«ng:** Ctrl+C

### OPTION 2: Cháº¡y Tá»± Ä‘á»™ng vá»›i Screen/Tmux

Sá»­ dá»¥ng `tmux` Ä‘á»ƒ cháº¡y nhiá»u processes:

```bash
# Install tmux (náº¿u chÆ°a cÃ³)
conda install -c conda-forge tmux -y

# Táº¡o session
tmux new -s bigdata

# Window 1: Market Producer
cd /home/jovyan/work/market_risk && python get_finance_data.py

# Táº¡o window má»›i: Ctrl+B, C
# Window 2: Market Consumer
cd /home/jovyan/work/market_risk && python spark_consumer.py

# Tiáº¿p tá»¥c táº¡o windows cho fraud producer, consumer, dashboard
# Navigate: Ctrl+B, N (next) / P (previous)
# Detach: Ctrl+B, D
# Reattach: tmux attach -t bigdata
```

## ğŸ“Š Monitoring & Verification

### 1. Kiá»ƒm tra Kafka Topics

```python
from kafka import KafkaConsumer
import json

# Consumer Ä‘á»ƒ xem messages
consumer = KafkaConsumer(
    'vietnam_stocks',
    bootstrap_servers=['kafka:9092'],
    auto_offset_reset='latest',
    value_deserializer=lambda m: json.loads(m.decode('utf-8'))
)

# Äá»c 5 messages
for i, message in enumerate(consumer):
    if i >= 5:
        break
    print(message.value)
```

### 2. Kiá»ƒm tra Redis Data

```python
import redis
import json

r = redis.Redis(host='redis', port=6379, decode_responses=True)

# Xem táº¥t cáº£ keys
keys = r.keys('*')
print(f"Total keys: {len(keys)}")

# Xem market data
market_keys = r.keys('market:latest:*')
for key in market_keys[:5]:
    data = json.loads(r.get(key))
    print(f"{data['symbol']}: {data['price']}")

# Xem fraud alerts
fraud_alerts = r.keys('fraud:alert:*')
print(f"Total fraud alerts: {len(fraud_alerts)}")
```

### 3. Kiá»ƒm tra Spark Jobs

Truy cáº­p Spark UI:
- Spark Master: http://localhost:8080
- Application UI: http://localhost:4040 (khi consumer Ä‘ang cháº¡y)

## ğŸ¨ Sá»­ dá»¥ng Dashboard

### Market Risk Tab

**Displays:**
- ğŸ“Š Summary cards (Total stocks, High risk, Avg volatility, Foreign flow)
- ğŸ“ˆ Price chart (top 5 stocks)
- âš ï¸ Risk score chart (by symbol)
- ğŸ“‰ Volatility chart
- ğŸ’° Foreign flow chart
- ğŸš¨ Risk alerts list

**Features:**
- Auto-refresh: 5s
- Interactive charts
- Real-time updates

### Fraud Detection Tab

**Displays:**
- ğŸ“Š Summary cards (Total TX, Fraud alerts, Fraud rate, Amount at risk)
- ğŸ“ˆ Fraud timeline chart
- ğŸ¥§ Distribution by TX type
- ğŸ“‹ Recent transactions table
- ğŸš¨ Fraud alerts list

**Features:**
- Auto-refresh: 5s
- Fraud highlighting
- Probability indicators

### Statistics Tab

**Displays:**
- Market statistics
- Fraud statistics
- Historical performance

## ğŸ”§ Troubleshooting

### Problem 1: Kafka Connection Failed

```python
# Error: NoBrokersAvailable
```

**Solution:**
```bash
# Kiá»ƒm tra Kafka service (trÃªn host)
docker-compose logs kafka

# Restart Kafka (trÃªn host)
docker-compose restart kafka zookeeper

# Äá»£i 30s Ä‘á»ƒ Kafka khá»Ÿi Ä‘á»™ng

# Test láº¡i trong container
from kafka import KafkaProducer
producer = KafkaProducer(bootstrap_servers=['kafka:9092'])
```

### Problem 2: Redis Connection Failed

```python
# Error: ConnectionError
```

**Solution:**
```bash
# Kiá»ƒm tra Redis (trÃªn host)
docker-compose logs redis

# Restart (trÃªn host)
docker-compose restart redis

# Test trong container
import redis
r = redis.Redis(host='redis', port=6379)
r.ping()
```

### Problem 3: HDFS File Not Found

```
# Error: Path does not exist: hdfs://namenode:9000/data/input/...
```

**Solution:**
```bash
# Tá»« host machine
docker exec namenode hdfs dfs -ls /data/input/

# Náº¿u khÃ´ng cÃ³ file
docker exec namenode hdfs dfs -mkdir -p /data/input
docker exec namenode hdfs dfs -put <local_file> /data/input/
```

### Problem 4: Model Not Found

```
# Error: Path does not exist: gbt_fraud_model
```

**Solution:**
```bash
cd /home/jovyan/work/fraud_detection

# Kiá»ƒm tra
ls -la | grep model

# Náº¿u khÃ´ng cÃ³, cáº§n train:
# 1. Cháº¡y preprocessing.ipynb
# 2. Cháº¡y train.ipynb
```

### Problem 5: vnstock API Error

```
# Error: Cannot fetch stock data
```

**Possible causes:**
- Thá»‹ trÆ°á»ng Ä‘Ã³ng cá»­a (chá»‰ má»Ÿ T2-T6, 9h-15h)
- Internet connection
- API rate limit

**Solution:**
```python
# Test vnstock
from vnstock3 import Vnstock
stock = Vnstock().stock(symbol='VCB', source='VCI')
df = stock.trading.price_board(symbols_list=['VCB'])
print(df)
```

### Problem 6: Port Already in Use

```
# Error: Address already in use: 8050
```

**Solution:**
```bash
# TÃ¬m process Ä‘ang dÃ¹ng port
lsof -i :8050

# Kill process
kill -9 <PID>

# Hoáº·c dÃ¹ng port khÃ¡c
python dashboard.py --port 8051
```

## ğŸ“ˆ Performance Tuning

### TÄƒng throughput Kafka Producer

```python
# Trong get_finance_data.py
TRANSACTIONS_PER_SECOND = 10  # TÄƒng tá»« 5 lÃªn 10
```

### TÄƒng batch size Spark

```python
# Trong spark_consumer.py
.trigger(processingTime="5 seconds")  # Giáº£m tá»« 15s xuá»‘ng 5s
```

### TÄƒng Redis memory

```bash
# Trong docker-compose.yml (trÃªn host)
redis:
  command: redis-server --maxmemory 512mb
```

## ğŸ¯ Testing Scenarios

### Scenario 1: Market Risk Alert

```python
# Táº¡o dá»¯ liá»‡u test vá»›i high risk
# Trong get_finance_data.py, modify data Ä‘á»ƒ risk_score > 2.5
# Dashboard sáº½ hiá»ƒn thá»‹ alert
```

### Scenario 2: Fraud Detection

```python
# Producer sáº½ tá»± Ä‘á»™ng Ä‘á»c dá»¯ liá»‡u cÃ³ fraud
# Xem fraud alerts trong Dashboard tab 2
# Kiá»ƒm tra accuracy trong console output
```

## ğŸ“ Logs & Debugging

### Enable Debug Logs

```python
# Trong má»—i file .py, thÃªm:
import logging
logging.basicConfig(level=logging.DEBUG)
```

### View Spark Logs

```bash
# Application logs
tail -f /tmp/spark*.log

# Hoáº·c xem trong Spark UI
```

### View Redis Logs

```bash
# Tá»« host
docker-compose logs -f redis
```

## ğŸ”„ Restart Everything

```bash
# Stop all Python processes
# Ctrl+C trong má»—i terminal

# Tá»« host, restart services
docker-compose restart

# Äá»£i 1 phÃºt Ä‘á»ƒ services khá»Ÿi Ä‘á»™ng

# VÃ o láº¡i container
docker exec -it pyspark-notebook bash

# Cháº¡y láº¡i tá»«ng component
```

## âœ… Verification Checklist

- [ ] Kafka producer Ä‘ang cháº¡y vÃ  gá»­i dá»¯ liá»‡u
- [ ] Spark consumer nháº­n Ä‘Æ°á»£c dá»¯ liá»‡u tá»« Kafka
- [ ] Redis cÃ³ dá»¯ liá»‡u (check báº±ng `redis-cli KEYS *`)
- [ ] Dashboard hiá»ƒn thá»‹ dá»¯ liá»‡u
- [ ] Dashboard auto-refresh hoáº¡t Ä‘á»™ng
- [ ] Fraud alerts hiá»ƒn thá»‹ (náº¿u cÃ³ fraud)
- [ ] Market risk alerts hiá»ƒn thá»‹ (náº¿u cÃ³ high risk)

## ğŸš€ Production Checklist

Náº¿u deploy production, cáº§n:

- [ ] Authentication cho táº¥t cáº£ services
- [ ] SSL/TLS encryption
- [ ] Monitoring (Prometheus, Grafana)
- [ ] Alerting system
- [ ] Backup strategy
- [ ] High availability setup
- [ ] Load balancing
- [ ] Security hardening

---

**ChÃºc báº¡n cháº¡y thÃ nh cÃ´ng! ğŸ‰**

CÃ³ váº¥n Ä‘á» gÃ¬, check láº¡i tá»«ng bÆ°á»›c hoáº·c xem logs Ä‘á»ƒ debug.
